{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kfu9giPQ77DL"
   },
   "source": [
    "# Deep Learning Project \\#1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VVRwR8OvAHWh"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKwP8MHeLPiW"
   },
   "source": [
    "Downloading the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "utETkXJKLPiW",
    "outputId": "8a29fdde-2df9-4048-b646-7fab5c40ba8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./CIFAR-10/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3547e396b90643bda7fbb90b812e159b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./CIFAR-10/cifar-10-python.tar.gz to ./CIFAR-10/\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainingdata = torchvision.datasets.CIFAR10('./CIFAR-10/',train=True,download=True)\n",
    "testdata = torchvision.datasets.CIFAR10('./CIFAR-10/',train=False,download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JEGOr1snLPiX"
   },
   "source": [
    "Mean and Std calculation for normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pv8F4mo4LPiY",
    "outputId": "cd7d149c-bbdf-49d9-d986-b98290246f76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49139968 0.48215841 0.44653091]\n",
      "[0.24703223 0.24348513 0.26158784]\n"
     ]
    }
   ],
   "source": [
    "tr_mean = trainingdata.data.mean(axis = (0,1,2)) / 255\n",
    "tr_std = trainingdata.data.std(axis = (0,1,2))  / 255\n",
    "print(tr_mean)\n",
    "print(tr_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "43O3-oLlur-U"
   },
   "source": [
    "Data Augmentation (Random Transforms and Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "vM26ebEMLPiZ"
   },
   "outputs": [],
   "source": [
    "tr_train = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.RandomCrop(size=[32,32], padding=4),\n",
    "        torchvision.transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n",
    "        torchvision.transforms.RandomRotation(10),\n",
    "        torchvision.transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        torchvision.transforms.RandomHorizontalFlip(),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(tr_mean, tr_std)\n",
    "    ])\n",
    "\n",
    "tr_test = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                          torchvision.transforms.Normalize(tr_mean, tr_std)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xsmTx0JLPiZ"
   },
   "source": [
    "Download the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "DqjmlixNCMlZ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainingdata = torchvision.datasets.CIFAR10('./CIFAR-10/',train=True,download=False,transform=tr_train)\n",
    "testdata = torchvision.datasets.CIFAR10('./CIFAR-10/',train=False,download=False,transform=tr_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8jilneICxoQ"
   },
   "source": [
    "Check how many Training and Test Data we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z2zHmiKRLPia",
    "outputId": "6f61aafc-9f4a-49ee-9f0a-80c9b189a8a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(trainingdata))\n",
    "print(len(testdata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nq_r5NZ6C4qp"
   },
   "source": [
    "Printing size of the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ESuk-dMuDI50",
    "outputId": "ffd10f6c-e8ea-462b-b185-3afc109466a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32]) 2\n"
     ]
    }
   ],
   "source": [
    "image, label = trainingdata[13]\n",
    "print(image.size(),label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fvOtVvprvLm0"
   },
   "source": [
    "We set up our data loaders.  \n",
    "We can try different Batch Sizes here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "hnES23k0EN4_"
   },
   "outputs": [],
   "source": [
    "trainDataLoader = torch.utils.data.DataLoader(trainingdata,batch_size=64,shuffle=True)\n",
    "testDataLoader = torch.utils.data.DataLoader(testdata,batch_size=64,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xm_XdCDE9bY"
   },
   "source": [
    "### Generic ResNet Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fJy4Ow0WJ6Te"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_planes, planes, kernel_size, skip_kernel_size, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size, stride=stride, padding=int((kernel_size-1)/2), bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size,\n",
    "                               stride=1, padding=int((kernel_size-1)/2), bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes,\n",
    "                          skip_kernel_size, stride=stride, padding=int((skip_kernel_size-1)/2), bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, N, num_blocks, C_1, conv_kernel_size, skip_kernel_size, avg_pool_size, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = C_1\n",
    "        self.avg_pool_size = avg_pool_size\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, C_1, conv_kernel_size[0],\n",
    "                               stride=1, padding=int((conv_kernel_size[0]-1)/2), bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(C_1)\n",
    "\n",
    "        res_layers = []\n",
    "        \n",
    "        for i in range(N):\n",
    "          if i == 0:\n",
    "            s = 1\n",
    "          else:\n",
    "            s = 2\n",
    "          res_layers.append(self._make_layer(block, (2**i)*C_1, num_blocks[i], conv_kernel_size[i], skip_kernel_size[i], stride=s))\n",
    "\n",
    "        self.layer = nn.Sequential(*res_layers)\n",
    "\n",
    "        ps = 2**(np.ceil(np.log2(avg_pool_size)))\n",
    "\n",
    "\n",
    "        self.linear = nn.Linear(int(C_1*32*32/(2**(N-1))/(ps**2)), num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, conv_kernel_size, skip_kernel_size, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, conv_kernel_size, skip_kernel_size, stride))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer(out)\n",
    "        out = F.avg_pool2d(out, self.avg_pool_size)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "def project1_model(N, num_blocks, C_1, conv_kernel_size, skip_kernel_size, avg_pool_size):\n",
    "    return ResNet(BasicBlock, N, num_blocks, C_1, conv_kernel_size, skip_kernel_size, avg_pool_size, num_classes=10)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rafgj5OtpPTw"
   },
   "source": [
    "### We defined our model in a parametric way\n",
    "\n",
    "So here we can set up our parameters.\n",
    "\n",
    "N: Number of residual layers, 3-4-5  \n",
    "C_1: # channels in the first layer  \n",
    "num_blocks: Nx1 vector, num_blocks[i] is number of residual blocks in layer i  \n",
    "conv_kernel_size: Nx1 vector, kernel size for conv layers in each residual layer  \n",
    "skip_kernel_size: Nx1 vector, kernel size for skip connections between each residual block  \n",
    "avg_pool_size: Kernel size for the average pooling at last layer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "m1OnvKd3pODw"
   },
   "outputs": [],
   "source": [
    "N = 3\n",
    "C_1 = 85\n",
    "num_blocks = [2]*N\n",
    "conv_kernel_size = [3]*N\n",
    "avg_pool_size = 8\n",
    "skip_kernel_size = [1]*N\n",
    "\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "s0b82L9650OV"
   },
   "outputs": [],
   "source": [
    "net = project1_model(N,\n",
    "                    num_blocks, \n",
    "                    C_1, \n",
    "                    conv_kernel_size,\n",
    "                    skip_kernel_size,\n",
    "                    avg_pool_size).cuda()\n",
    "Loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YBwC6_r2LPie"
   },
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "FehBnwmzC-WN",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "ResNet                                        --                        --\n",
       "├─Conv2d: 1-1                                 [1, 85, 32, 32]           2,295\n",
       "├─BatchNorm2d: 1-2                            [1, 85, 32, 32]           170\n",
       "├─Sequential: 1-3                             [1, 340, 8, 8]            --\n",
       "│    └─Sequential: 2-1                        [1, 85, 32, 32]           --\n",
       "│    │    └─BasicBlock: 3-1                   [1, 85, 32, 32]           130,390\n",
       "│    │    └─BasicBlock: 3-2                   [1, 85, 32, 32]           130,390\n",
       "│    └─Sequential: 2-2                        [1, 170, 16, 16]          --\n",
       "│    │    └─BasicBlock: 3-3                   [1, 170, 16, 16]          405,620\n",
       "│    │    └─BasicBlock: 3-4                   [1, 170, 16, 16]          520,880\n",
       "│    └─Sequential: 2-3                        [1, 340, 8, 8]            --\n",
       "│    │    └─BasicBlock: 3-5                   [1, 340, 8, 8]            1,620,440\n",
       "│    │    └─BasicBlock: 3-6                   [1, 340, 8, 8]            2,082,160\n",
       "├─Linear: 1-4                                 [1, 10]                   3,410\n",
       "===============================================================================================\n",
       "Total params: 4,895,755\n",
       "Trainable params: 4,895,755\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 742.20\n",
       "===============================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 12.19\n",
       "Params size (MB): 19.58\n",
       "Estimated Total Size (MB): 31.78\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary of the model\n",
    "from torchinfo import summary\n",
    "from torchvision import models\n",
    "\n",
    "summary(net,(1,3,32,32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xs9-dDLsKFrc"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "sK-nrVWWLPie"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def neural_net(N,C1,num_blocks,conv_kernel_size,avg_pool_size,skip_kernel_size):\n",
    "    net = project1_model(N,\n",
    "                    num_blocks, \n",
    "                    C1, \n",
    "                    conv_kernel_size,\n",
    "                    skip_kernel_size,\n",
    "                    avg_pool_size).cuda()\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "R91mQxBBLPif"
   },
   "outputs": [],
   "source": [
    "Grid_Search = ((2,1,256), #1\n",
    "              (2,2,172), #2\n",
    "              (2,3,140), #3\n",
    "              (2,4,120), #4\n",
    "              (2,5,106), #5\n",
    "              (2,6,96),  #6\n",
    "              (2,7,90),  #7\n",
    "              (3,1,128), #8\n",
    "              (3,2,85),  #9\n",
    "              (3,3,68),  #10\n",
    "              (3,4,58),  #11\n",
    "              (3,5,52),  #12\n",
    "              (4,1,64),  #13\n",
    "              (4,2,42),  #14\n",
    "              (4,3,32),  #15\n",
    "              (4,4,29),  #16\n",
    "              (4,5,26),  #17\n",
    "              (5,1,32),  #18\n",
    "              (5,2,21),  #19\n",
    "              (5,3,17),  #20\n",
    "              (5,4,14),  #21\n",
    "              (5,5,13))  #22\n",
    "\n",
    "Num_Runs = len(Grid_Search)\n",
    "Num_Epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "oOpbFRl_LPif"
   },
   "outputs": [],
   "source": [
    "train_loss_history = np.zeros([Num_Runs, Num_Epochs])\n",
    "test_loss_history = np.zeros([Num_Runs, Num_Epochs])\n",
    "train_acc_history = np.zeros([Num_Runs, Num_Epochs])\n",
    "test_acc_history = np.zeros([Num_Runs, Num_Epochs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4yluM93iLPif"
   },
   "source": [
    "# START EDITING FROM HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aCgFJqs6LPif",
    "outputId": "100b4247-c031-4456-890b-ad16b2f09491"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Number: 1 Starts Here\n",
      "Epoch: 0 \tTrain Loss: 1.61690 \tTrain Acc: 0.3988 \tTest Loss: 1.43155 \tTest Acc: 0.4908 \tTime: 132.7520\n",
      "Epoch: 1 \tTrain Loss: 1.29677 \tTrain Acc: 0.5353 \tTest Loss: 1.32635 \tTest Acc: 0.5383 \tTime: 132.3871\n",
      "Epoch: 2 \tTrain Loss: 1.15550 \tTrain Acc: 0.5913 \tTest Loss: 1.13582 \tTest Acc: 0.6066 \tTime: 132.3256\n",
      "Epoch: 3 \tTrain Loss: 1.07145 \tTrain Acc: 0.6204 \tTest Loss: 1.15049 \tTest Acc: 0.6104 \tTime: 132.1676\n",
      "Epoch: 4 \tTrain Loss: 0.98373 \tTrain Acc: 0.6556 \tTest Loss: 0.96248 \tTest Acc: 0.6645 \tTime: 132.0584\n",
      "Epoch: 5 \tTrain Loss: 0.90878 \tTrain Acc: 0.6825 \tTest Loss: 0.91594 \tTest Acc: 0.6867 \tTime: 132.1401\n",
      "Epoch: 6 \tTrain Loss: 0.85890 \tTrain Acc: 0.7001 \tTest Loss: 0.81027 \tTest Acc: 0.7192 \tTime: 132.0490\n",
      "Epoch: 7 \tTrain Loss: 0.80593 \tTrain Acc: 0.7204 \tTest Loss: 0.80606 \tTest Acc: 0.7276 \tTime: 132.0495\n",
      "Epoch: 8 \tTrain Loss: 0.76922 \tTrain Acc: 0.7334 \tTest Loss: 0.81162 \tTest Acc: 0.7216 \tTime: 131.6814\n",
      "Epoch: 9 \tTrain Loss: 0.72773 \tTrain Acc: 0.7482 \tTest Loss: 0.74298 \tTest Acc: 0.7468 \tTime: 131.6929\n",
      "Epoch: 10 \tTrain Loss: 0.68495 \tTrain Acc: 0.7620 \tTest Loss: 0.65987 \tTest Acc: 0.7799 \tTime: 131.9218\n",
      "Epoch: 11 \tTrain Loss: 0.65752 \tTrain Acc: 0.7732 \tTest Loss: 0.69494 \tTest Acc: 0.7703 \tTime: 131.9795\n",
      "Epoch: 12 \tTrain Loss: 0.62845 \tTrain Acc: 0.7836 \tTest Loss: 0.65458 \tTest Acc: 0.7821 \tTime: 131.8198\n",
      "Epoch: 13 \tTrain Loss: 0.60590 \tTrain Acc: 0.7919 \tTest Loss: 0.63000 \tTest Acc: 0.7831 \tTime: 132.2034\n",
      "Epoch: 14 \tTrain Loss: 0.58334 \tTrain Acc: 0.8000 \tTest Loss: 0.60535 \tTest Acc: 0.8004 \tTime: 132.2506\n",
      "Epoch: 15 \tTrain Loss: 0.55123 \tTrain Acc: 0.8109 \tTest Loss: 0.60824 \tTest Acc: 0.7929 \tTime: 132.0345\n",
      "Epoch: 16 \tTrain Loss: 0.53001 \tTrain Acc: 0.8172 \tTest Loss: 0.56852 \tTest Acc: 0.8084 \tTime: 132.2213\n",
      "Epoch: 17 \tTrain Loss: 0.51435 \tTrain Acc: 0.8235 \tTest Loss: 0.54908 \tTest Acc: 0.8156 \tTime: 132.1735\n",
      "Epoch: 18 \tTrain Loss: 0.50262 \tTrain Acc: 0.8266 \tTest Loss: 0.59712 \tTest Acc: 0.8008 \tTime: 132.2663\n",
      "Epoch: 19 \tTrain Loss: 0.48979 \tTrain Acc: 0.8316 \tTest Loss: 0.53126 \tTest Acc: 0.8206 \tTime: 131.7861\n",
      "Epoch: 20 \tTrain Loss: 0.46505 \tTrain Acc: 0.8414 \tTest Loss: 0.50400 \tTest Acc: 0.8345 \tTime: 131.8446\n",
      "Epoch: 21 \tTrain Loss: 0.45222 \tTrain Acc: 0.8448 \tTest Loss: 0.51326 \tTest Acc: 0.8288 \tTime: 131.8504\n",
      "Epoch: 22 \tTrain Loss: 0.44218 \tTrain Acc: 0.8482 \tTest Loss: 0.50325 \tTest Acc: 0.8357 \tTime: 132.1176\n",
      "Epoch: 23 \tTrain Loss: 0.42664 \tTrain Acc: 0.8527 \tTest Loss: 0.50872 \tTest Acc: 0.8360 \tTime: 131.9589\n",
      "Epoch: 24 \tTrain Loss: 0.41700 \tTrain Acc: 0.8559 \tTest Loss: 0.50547 \tTest Acc: 0.8350 \tTime: 131.8899\n",
      "Epoch: 25 \tTrain Loss: 0.40039 \tTrain Acc: 0.8615 \tTest Loss: 0.48353 \tTest Acc: 0.8379 \tTime: 132.2178\n",
      "Epoch: 26 \tTrain Loss: 0.39558 \tTrain Acc: 0.8641 \tTest Loss: 0.47777 \tTest Acc: 0.8451 \tTime: 132.0797\n",
      "Epoch: 27 \tTrain Loss: 0.37967 \tTrain Acc: 0.8698 \tTest Loss: 0.50545 \tTest Acc: 0.8346 \tTime: 132.4252\n",
      "Epoch: 28 \tTrain Loss: 0.36986 \tTrain Acc: 0.8722 \tTest Loss: 0.48180 \tTest Acc: 0.8406 \tTime: 132.2567\n",
      "Epoch: 29 \tTrain Loss: 0.36434 \tTrain Acc: 0.8744 \tTest Loss: 0.50346 \tTest Acc: 0.8370 \tTime: 132.2353\n",
      "Epoch: 30 \tTrain Loss: 0.34931 \tTrain Acc: 0.8796 \tTest Loss: 0.47717 \tTest Acc: 0.8500 \tTime: 132.3180\n",
      "Epoch: 31 \tTrain Loss: 0.34543 \tTrain Acc: 0.8806 \tTest Loss: 0.47983 \tTest Acc: 0.8416 \tTime: 132.3754\n",
      "Epoch: 32 \tTrain Loss: 0.33522 \tTrain Acc: 0.8851 \tTest Loss: 0.49601 \tTest Acc: 0.8425 \tTime: 132.4225\n",
      "Epoch: 33 \tTrain Loss: 0.32656 \tTrain Acc: 0.8873 \tTest Loss: 0.48199 \tTest Acc: 0.8480 \tTime: 132.1801\n",
      "Epoch: 34 \tTrain Loss: 0.31975 \tTrain Acc: 0.8904 \tTest Loss: 0.46574 \tTest Acc: 0.8463 \tTime: 132.0398\n",
      "Epoch: 35 \tTrain Loss: 0.30128 \tTrain Acc: 0.8980 \tTest Loss: 0.45424 \tTest Acc: 0.8549 \tTime: 132.0861\n",
      "Epoch: 36 \tTrain Loss: 0.30038 \tTrain Acc: 0.8959 \tTest Loss: 0.47005 \tTest Acc: 0.8506 \tTime: 132.2611\n",
      "Epoch: 37 \tTrain Loss: 0.29616 \tTrain Acc: 0.8963 \tTest Loss: 0.45425 \tTest Acc: 0.8539 \tTime: 131.7684\n",
      "Epoch: 38 \tTrain Loss: 0.28756 \tTrain Acc: 0.8989 \tTest Loss: 0.46563 \tTest Acc: 0.8528 \tTime: 131.8643\n",
      "Epoch: 39 \tTrain Loss: 0.28392 \tTrain Acc: 0.9011 \tTest Loss: 0.45695 \tTest Acc: 0.8559 \tTime: 131.9948\n",
      "Epoch: 40 \tTrain Loss: 0.26955 \tTrain Acc: 0.9069 \tTest Loss: 0.47056 \tTest Acc: 0.8510 \tTime: 131.8949\n",
      "Epoch: 41 \tTrain Loss: 0.26450 \tTrain Acc: 0.9077 \tTest Loss: 0.47458 \tTest Acc: 0.8508 \tTime: 131.9523\n",
      "Epoch: 42 \tTrain Loss: 0.25847 \tTrain Acc: 0.9106 \tTest Loss: 0.46466 \tTest Acc: 0.8564 \tTime: 132.0205\n",
      "Epoch: 43 \tTrain Loss: 0.25620 \tTrain Acc: 0.9111 \tTest Loss: 0.45594 \tTest Acc: 0.8578 \tTime: 132.1559\n",
      "Epoch: 44 \tTrain Loss: 0.25693 \tTrain Acc: 0.9114 \tTest Loss: 0.44298 \tTest Acc: 0.8615 \tTime: 132.3365\n",
      "Epoch: 45 \tTrain Loss: 0.24545 \tTrain Acc: 0.9154 \tTest Loss: 0.45098 \tTest Acc: 0.8565 \tTime: 132.1832\n",
      "Epoch: 46 \tTrain Loss: 0.23819 \tTrain Acc: 0.9171 \tTest Loss: 0.42870 \tTest Acc: 0.8668 \tTime: 132.8230\n",
      "Epoch: 47 \tTrain Loss: 0.23121 \tTrain Acc: 0.9198 \tTest Loss: 0.47969 \tTest Acc: 0.8526 \tTime: 132.5139\n",
      "Epoch: 48 \tTrain Loss: 0.23227 \tTrain Acc: 0.9195 \tTest Loss: 0.44378 \tTest Acc: 0.8621 \tTime: 132.3112\n",
      "Epoch: 49 \tTrain Loss: 0.23049 \tTrain Acc: 0.9211 \tTest Loss: 0.43824 \tTest Acc: 0.8644 \tTime: 132.4678\n",
      "Total Time For This Run: 6606.8675\n",
      "Run Number: 2 Starts Here\n",
      "Epoch: 0 \tTrain Loss: 1.61566 \tTrain Acc: 0.4016 \tTest Loss: 1.38820 \tTest Acc: 0.5007 \tTime: 187.0635\n",
      "Epoch: 1 \tTrain Loss: 1.23571 \tTrain Acc: 0.5574 \tTest Loss: 1.29053 \tTest Acc: 0.5485 \tTime: 187.0686\n",
      "Epoch: 2 \tTrain Loss: 1.07701 \tTrain Acc: 0.6199 \tTest Loss: 1.13342 \tTest Acc: 0.6127 \tTime: 186.7069\n",
      "Epoch: 3 \tTrain Loss: 0.97197 \tTrain Acc: 0.6578 \tTest Loss: 0.95401 \tTest Acc: 0.6716 \tTime: 186.6756\n",
      "Epoch: 4 \tTrain Loss: 0.88816 \tTrain Acc: 0.6915 \tTest Loss: 0.85447 \tTest Acc: 0.7027 \tTime: 186.3865\n",
      "Epoch: 5 \tTrain Loss: 0.80356 \tTrain Acc: 0.7215 \tTest Loss: 0.81906 \tTest Acc: 0.7197 \tTime: 186.4796\n",
      "Epoch: 6 \tTrain Loss: 0.74220 \tTrain Acc: 0.7434 \tTest Loss: 0.72688 \tTest Acc: 0.7547 \tTime: 186.5656\n",
      "Epoch: 7 \tTrain Loss: 0.69099 \tTrain Acc: 0.7599 \tTest Loss: 0.65918 \tTest Acc: 0.7703 \tTime: 187.2658\n",
      "Epoch: 8 \tTrain Loss: 0.64736 \tTrain Acc: 0.7761 \tTest Loss: 0.57469 \tTest Acc: 0.8000 \tTime: 187.2343\n",
      "Epoch: 9 \tTrain Loss: 0.60727 \tTrain Acc: 0.7911 \tTest Loss: 0.58159 \tTest Acc: 0.8031 \tTime: 187.3983\n",
      "Epoch: 10 \tTrain Loss: 0.56351 \tTrain Acc: 0.8043 \tTest Loss: 0.55733 \tTest Acc: 0.8068 \tTime: 187.0207\n",
      "Epoch: 11 \tTrain Loss: 0.52851 \tTrain Acc: 0.8178 \tTest Loss: 0.53891 \tTest Acc: 0.8164 \tTime: 187.1212\n",
      "Epoch: 12 \tTrain Loss: 0.50060 \tTrain Acc: 0.8268 \tTest Loss: 0.52039 \tTest Acc: 0.8241 \tTime: 186.9005\n",
      "Epoch: 13 \tTrain Loss: 0.47575 \tTrain Acc: 0.8355 \tTest Loss: 0.49804 \tTest Acc: 0.8304 \tTime: 186.9743\n",
      "Epoch: 14 \tTrain Loss: 0.46023 \tTrain Acc: 0.8409 \tTest Loss: 0.45346 \tTest Acc: 0.8468 \tTime: 186.7776\n",
      "Epoch: 15 \tTrain Loss: 0.42761 \tTrain Acc: 0.8516 \tTest Loss: 0.43592 \tTest Acc: 0.8542 \tTime: 186.6481\n",
      "Epoch: 16 \tTrain Loss: 0.40793 \tTrain Acc: 0.8599 \tTest Loss: 0.45025 \tTest Acc: 0.8438 \tTime: 186.5237\n",
      "Epoch: 17 \tTrain Loss: 0.39297 \tTrain Acc: 0.8639 \tTest Loss: 0.41184 \tTest Acc: 0.8589 \tTime: 186.7608\n",
      "Epoch: 18 \tTrain Loss: 0.38195 \tTrain Acc: 0.8677 \tTest Loss: 0.39868 \tTest Acc: 0.8668 \tTime: 186.9145\n",
      "Epoch: 19 \tTrain Loss: 0.36281 \tTrain Acc: 0.8731 \tTest Loss: 0.43577 \tTest Acc: 0.8564 \tTime: 186.7236\n",
      "Epoch: 20 \tTrain Loss: 0.34106 \tTrain Acc: 0.8812 \tTest Loss: 0.38218 \tTest Acc: 0.8748 \tTime: 187.2307\n",
      "Epoch: 21 \tTrain Loss: 0.32371 \tTrain Acc: 0.8873 \tTest Loss: 0.40860 \tTest Acc: 0.8640 \tTime: 186.9398\n",
      "Epoch: 22 \tTrain Loss: 0.31798 \tTrain Acc: 0.8890 \tTest Loss: 0.37586 \tTest Acc: 0.8730 \tTime: 186.8180\n",
      "Epoch: 23 \tTrain Loss: 0.30793 \tTrain Acc: 0.8942 \tTest Loss: 0.38911 \tTest Acc: 0.8738 \tTime: 187.3509\n",
      "Epoch: 24 \tTrain Loss: 0.29889 \tTrain Acc: 0.8963 \tTest Loss: 0.37195 \tTest Acc: 0.8781 \tTime: 186.8161\n",
      "Epoch: 25 \tTrain Loss: 0.27364 \tTrain Acc: 0.9042 \tTest Loss: 0.36689 \tTest Acc: 0.8841 \tTime: 186.9349\n",
      "Epoch: 26 \tTrain Loss: 0.26827 \tTrain Acc: 0.9050 \tTest Loss: 0.36797 \tTest Acc: 0.8813 \tTime: 186.5404\n",
      "Epoch: 27 \tTrain Loss: 0.25901 \tTrain Acc: 0.9084 \tTest Loss: 0.34773 \tTest Acc: 0.8892 \tTime: 186.8237\n",
      "Epoch: 28 \tTrain Loss: 0.25832 \tTrain Acc: 0.9098 \tTest Loss: 0.34751 \tTest Acc: 0.8829 \tTime: 186.5327\n",
      "Epoch: 29 \tTrain Loss: 0.24637 \tTrain Acc: 0.9144 \tTest Loss: 0.36007 \tTest Acc: 0.8810 \tTime: 186.4980\n",
      "Epoch: 30 \tTrain Loss: 0.22839 \tTrain Acc: 0.9206 \tTest Loss: 0.36393 \tTest Acc: 0.8835 \tTime: 186.6446\n",
      "Epoch: 31 \tTrain Loss: 0.22176 \tTrain Acc: 0.9238 \tTest Loss: 0.35452 \tTest Acc: 0.8845 \tTime: 186.6024\n",
      "Epoch: 32 \tTrain Loss: 0.21867 \tTrain Acc: 0.9239 \tTest Loss: 0.35045 \tTest Acc: 0.8869 \tTime: 186.5798\n",
      "Epoch: 33 \tTrain Loss: 0.20886 \tTrain Acc: 0.9270 \tTest Loss: 0.35265 \tTest Acc: 0.8858 \tTime: 186.7624\n",
      "Epoch: 34 \tTrain Loss: 0.20184 \tTrain Acc: 0.9297 \tTest Loss: 0.36375 \tTest Acc: 0.8832 \tTime: 186.7563\n",
      "Epoch: 35 \tTrain Loss: 0.19467 \tTrain Acc: 0.9321 \tTest Loss: 0.34540 \tTest Acc: 0.8920 \tTime: 186.5872\n",
      "Epoch: 36 \tTrain Loss: 0.18532 \tTrain Acc: 0.9345 \tTest Loss: 0.36606 \tTest Acc: 0.8842 \tTime: 186.7373\n",
      "Epoch: 37 \tTrain Loss: 0.17794 \tTrain Acc: 0.9379 \tTest Loss: 0.35239 \tTest Acc: 0.8869 \tTime: 186.9348\n",
      "Epoch: 38 \tTrain Loss: 0.17693 \tTrain Acc: 0.9374 \tTest Loss: 0.35671 \tTest Acc: 0.8890 \tTime: 187.0031\n",
      "Epoch: 39 \tTrain Loss: 0.16892 \tTrain Acc: 0.9413 \tTest Loss: 0.34349 \tTest Acc: 0.8936 \tTime: 187.1050\n",
      "Epoch: 40 \tTrain Loss: 0.16217 \tTrain Acc: 0.9428 \tTest Loss: 0.34075 \tTest Acc: 0.8964 \tTime: 187.1044\n",
      "Epoch: 41 \tTrain Loss: 0.15486 \tTrain Acc: 0.9455 \tTest Loss: 0.34742 \tTest Acc: 0.8954 \tTime: 186.8941\n",
      "Epoch: 42 \tTrain Loss: 0.14894 \tTrain Acc: 0.9472 \tTest Loss: 0.35166 \tTest Acc: 0.8928 \tTime: 186.9202\n",
      "Epoch: 43 \tTrain Loss: 0.14794 \tTrain Acc: 0.9479 \tTest Loss: 0.34671 \tTest Acc: 0.8940 \tTime: 187.1065\n",
      "Epoch: 44 \tTrain Loss: 0.14991 \tTrain Acc: 0.9471 \tTest Loss: 0.34089 \tTest Acc: 0.8974 \tTime: 187.0962\n",
      "Epoch: 45 \tTrain Loss: 0.13608 \tTrain Acc: 0.9528 \tTest Loss: 0.35214 \tTest Acc: 0.8938 \tTime: 187.3831\n",
      "Epoch: 46 \tTrain Loss: 0.12933 \tTrain Acc: 0.9544 \tTest Loss: 0.36461 \tTest Acc: 0.8926 \tTime: 187.4114\n",
      "Epoch: 47 \tTrain Loss: 0.13240 \tTrain Acc: 0.9536 \tTest Loss: 0.35721 \tTest Acc: 0.8923 \tTime: 187.0828\n",
      "Epoch: 48 \tTrain Loss: 0.13187 \tTrain Acc: 0.9527 \tTest Loss: 0.35349 \tTest Acc: 0.8979 \tTime: 187.1827\n",
      "Epoch: 49 \tTrain Loss: 0.12670 \tTrain Acc: 0.9556 \tTest Loss: 0.36220 \tTest Acc: 0.8926 \tTime: 187.2383\n",
      "Total Time For This Run: 9344.8835\n",
      "Run Number: 3 Starts Here\n",
      "Epoch: 0 \tTrain Loss: 1.59336 \tTrain Acc: 0.4069 \tTest Loss: 1.31715 \tTest Acc: 0.5245 \tTime: 197.8848\n",
      "Epoch: 1 \tTrain Loss: 1.21990 \tTrain Acc: 0.5589 \tTest Loss: 1.24019 \tTest Acc: 0.5668 \tTime: 197.8503\n",
      "Epoch: 2 \tTrain Loss: 1.04700 \tTrain Acc: 0.6285 \tTest Loss: 1.09335 \tTest Acc: 0.6275 \tTime: 197.6942\n",
      "Epoch: 3 \tTrain Loss: 0.94037 \tTrain Acc: 0.6694 \tTest Loss: 0.86790 \tTest Acc: 0.6966 \tTime: 197.5510\n",
      "Epoch: 4 \tTrain Loss: 0.84901 \tTrain Acc: 0.7035 \tTest Loss: 0.84888 \tTest Acc: 0.7047 \tTime: 197.7287\n",
      "Epoch: 5 \tTrain Loss: 0.76405 \tTrain Acc: 0.7345 \tTest Loss: 0.73821 \tTest Acc: 0.7427 \tTime: 197.8744\n",
      "Epoch: 6 \tTrain Loss: 0.69342 \tTrain Acc: 0.7606 \tTest Loss: 0.66721 \tTest Acc: 0.7629 \tTime: 197.9968\n",
      "Epoch: 7 \tTrain Loss: 0.64068 \tTrain Acc: 0.7776 \tTest Loss: 0.63093 \tTest Acc: 0.7851 \tTime: 198.0795\n",
      "Epoch: 8 \tTrain Loss: 0.59950 \tTrain Acc: 0.7927 \tTest Loss: 0.57525 \tTest Acc: 0.8021 \tTime: 197.9936\n",
      "Epoch: 9 \tTrain Loss: 0.56247 \tTrain Acc: 0.8058 \tTest Loss: 0.54025 \tTest Acc: 0.8135 \tTime: 197.8651\n",
      "Epoch: 10 \tTrain Loss: 0.52194 \tTrain Acc: 0.8194 \tTest Loss: 0.49248 \tTest Acc: 0.8316 \tTime: 198.0954\n",
      "Epoch: 11 \tTrain Loss: 0.49340 \tTrain Acc: 0.8296 \tTest Loss: 0.47009 \tTest Acc: 0.8434 \tTime: 198.1207\n",
      "Epoch: 12 \tTrain Loss: 0.47536 \tTrain Acc: 0.8360 \tTest Loss: 0.44130 \tTest Acc: 0.8527 \tTime: 197.9850\n",
      "Epoch: 13 \tTrain Loss: 0.44155 \tTrain Acc: 0.8471 \tTest Loss: 0.44573 \tTest Acc: 0.8464 \tTime: 197.7643\n",
      "Epoch: 14 \tTrain Loss: 0.42741 \tTrain Acc: 0.8516 \tTest Loss: 0.44290 \tTest Acc: 0.8499 \tTime: 197.8256\n",
      "Epoch: 15 \tTrain Loss: 0.39823 \tTrain Acc: 0.8623 \tTest Loss: 0.42037 \tTest Acc: 0.8543 \tTime: 197.5700\n",
      "Epoch: 16 \tTrain Loss: 0.38162 \tTrain Acc: 0.8681 \tTest Loss: 0.38889 \tTest Acc: 0.8649 \tTime: 197.8232\n",
      "Epoch: 17 \tTrain Loss: 0.36393 \tTrain Acc: 0.8741 \tTest Loss: 0.40134 \tTest Acc: 0.8662 \tTime: 197.8073\n",
      "Epoch: 18 \tTrain Loss: 0.35582 \tTrain Acc: 0.8754 \tTest Loss: 0.40025 \tTest Acc: 0.8621 \tTime: 197.8510\n",
      "Epoch: 19 \tTrain Loss: 0.33543 \tTrain Acc: 0.8825 \tTest Loss: 0.39835 \tTest Acc: 0.8691 \tTime: 197.9321\n",
      "Epoch: 20 \tTrain Loss: 0.32152 \tTrain Acc: 0.8894 \tTest Loss: 0.35517 \tTest Acc: 0.8802 \tTime: 198.0840\n",
      "Epoch: 21 \tTrain Loss: 0.30323 \tTrain Acc: 0.8951 \tTest Loss: 0.36109 \tTest Acc: 0.8794 \tTime: 198.2310\n",
      "Epoch: 22 \tTrain Loss: 0.29725 \tTrain Acc: 0.8957 \tTest Loss: 0.35625 \tTest Acc: 0.8817 \tTime: 197.8474\n",
      "Epoch: 23 \tTrain Loss: 0.28429 \tTrain Acc: 0.8999 \tTest Loss: 0.37705 \tTest Acc: 0.8775 \tTime: 197.9686\n",
      "Epoch: 24 \tTrain Loss: 0.27585 \tTrain Acc: 0.9031 \tTest Loss: 0.34485 \tTest Acc: 0.8850 \tTime: 197.9509\n",
      "Epoch: 25 \tTrain Loss: 0.26045 \tTrain Acc: 0.9098 \tTest Loss: 0.33423 \tTest Acc: 0.8903 \tTime: 197.8152\n",
      "Epoch: 26 \tTrain Loss: 0.25039 \tTrain Acc: 0.9133 \tTest Loss: 0.33833 \tTest Acc: 0.8870 \tTime: 197.8250\n",
      "Epoch: 27 \tTrain Loss: 0.24045 \tTrain Acc: 0.9161 \tTest Loss: 0.34179 \tTest Acc: 0.8891 \tTime: 197.6062\n",
      "Epoch: 28 \tTrain Loss: 0.23377 \tTrain Acc: 0.9184 \tTest Loss: 0.32742 \tTest Acc: 0.8940 \tTime: 197.6906\n",
      "Epoch: 29 \tTrain Loss: 0.23481 \tTrain Acc: 0.9185 \tTest Loss: 0.33864 \tTest Acc: 0.8907 \tTime: 197.5994\n",
      "Epoch: 30 \tTrain Loss: 0.21196 \tTrain Acc: 0.9247 \tTest Loss: 0.31128 \tTest Acc: 0.8964 \tTime: 197.9512\n",
      "Epoch: 31 \tTrain Loss: 0.20758 \tTrain Acc: 0.9283 \tTest Loss: 0.31376 \tTest Acc: 0.8976 \tTime: 197.9509\n",
      "Epoch: 32 \tTrain Loss: 0.19862 \tTrain Acc: 0.9307 \tTest Loss: 0.32820 \tTest Acc: 0.8979 \tTime: 198.2461\n",
      "Epoch: 33 \tTrain Loss: 0.19574 \tTrain Acc: 0.9312 \tTest Loss: 0.34621 \tTest Acc: 0.8916 \tTime: 198.1246\n",
      "Epoch: 34 \tTrain Loss: 0.19367 \tTrain Acc: 0.9320 \tTest Loss: 0.32456 \tTest Acc: 0.9002 \tTime: 197.8920\n",
      "Epoch: 35 \tTrain Loss: 0.17947 \tTrain Acc: 0.9367 \tTest Loss: 0.32909 \tTest Acc: 0.8998 \tTime: 197.7064\n",
      "Epoch: 36 \tTrain Loss: 0.17565 \tTrain Acc: 0.9381 \tTest Loss: 0.33241 \tTest Acc: 0.8969 \tTime: 197.6598\n",
      "Epoch: 37 \tTrain Loss: 0.17146 \tTrain Acc: 0.9402 \tTest Loss: 0.32942 \tTest Acc: 0.8969 \tTime: 197.7025\n",
      "Epoch: 38 \tTrain Loss: 0.16321 \tTrain Acc: 0.9421 \tTest Loss: 0.32905 \tTest Acc: 0.8972 \tTime: 197.4622\n",
      "Epoch: 39 \tTrain Loss: 0.16113 \tTrain Acc: 0.9439 \tTest Loss: 0.33497 \tTest Acc: 0.8996 \tTime: 196.7157\n",
      "Epoch: 40 \tTrain Loss: 0.14841 \tTrain Acc: 0.9475 \tTest Loss: 0.31751 \tTest Acc: 0.9064 \tTime: 196.5452\n",
      "Epoch: 41 \tTrain Loss: 0.14595 \tTrain Acc: 0.9503 \tTest Loss: 0.32159 \tTest Acc: 0.9051 \tTime: 196.5215\n",
      "Epoch: 42 \tTrain Loss: 0.14258 \tTrain Acc: 0.9504 \tTest Loss: 0.31721 \tTest Acc: 0.9048 \tTime: 197.9775\n",
      "Epoch: 43 \tTrain Loss: 0.13651 \tTrain Acc: 0.9520 \tTest Loss: 0.31592 \tTest Acc: 0.9049 \tTime: 196.7127\n",
      "Epoch: 44 \tTrain Loss: 0.13693 \tTrain Acc: 0.9529 \tTest Loss: 0.31484 \tTest Acc: 0.9064 \tTime: 196.5634\n",
      "Epoch: 45 \tTrain Loss: 0.12938 \tTrain Acc: 0.9536 \tTest Loss: 0.32106 \tTest Acc: 0.9036 \tTime: 197.3978\n",
      "Epoch: 46 \tTrain Loss: 0.12362 \tTrain Acc: 0.9569 \tTest Loss: 0.31572 \tTest Acc: 0.9066 \tTime: 197.3095\n",
      "Epoch: 47 \tTrain Loss: 0.12155 \tTrain Acc: 0.9579 \tTest Loss: 0.31969 \tTest Acc: 0.9061 \tTime: 196.5130\n",
      "Epoch: 48 \tTrain Loss: 0.12104 \tTrain Acc: 0.9578 \tTest Loss: 0.34359 \tTest Acc: 0.9045 \tTime: 196.6973\n",
      "Epoch: 49 \tTrain Loss: 0.11662 \tTrain Acc: 0.9587 \tTest Loss: 0.31886 \tTest Acc: 0.9066 \tTime: 196.2731\n",
      "Total Time For This Run: 9881.8986\n",
      "Run Number: 4 Starts Here\n",
      "Epoch: 0 \tTrain Loss: 1.63992 \tTrain Acc: 0.3919 \tTest Loss: 1.55077 \tTest Acc: 0.4550 \tTime: 179.5845\n",
      "Epoch: 1 \tTrain Loss: 1.24093 \tTrain Acc: 0.5523 \tTest Loss: 1.22756 \tTest Acc: 0.5767 \tTime: 180.2661\n",
      "Epoch: 2 \tTrain Loss: 1.07280 \tTrain Acc: 0.6204 \tTest Loss: 1.14403 \tTest Acc: 0.6118 \tTime: 179.4070\n",
      "Epoch: 3 \tTrain Loss: 0.96318 \tTrain Acc: 0.6586 \tTest Loss: 0.96279 \tTest Acc: 0.6683 \tTime: 179.6053\n",
      "Epoch: 4 \tTrain Loss: 0.87134 \tTrain Acc: 0.6952 \tTest Loss: 0.89907 \tTest Acc: 0.6867 \tTime: 179.3905\n",
      "Epoch: 5 \tTrain Loss: 0.78911 \tTrain Acc: 0.7254 \tTest Loss: 0.73313 \tTest Acc: 0.7461 \tTime: 179.5158\n",
      "Epoch: 6 \tTrain Loss: 0.73127 \tTrain Acc: 0.7472 \tTest Loss: 0.75950 \tTest Acc: 0.7418 \tTime: 179.7415\n",
      "Epoch: 7 \tTrain Loss: 0.67293 \tTrain Acc: 0.7660 \tTest Loss: 0.70303 \tTest Acc: 0.7573 \tTime: 180.5279\n",
      "Epoch: 8 \tTrain Loss: 0.63488 \tTrain Acc: 0.7798 \tTest Loss: 0.67091 \tTest Acc: 0.7721 \tTime: 179.9773\n",
      "Epoch: 9 \tTrain Loss: 0.59032 \tTrain Acc: 0.7953 \tTest Loss: 0.56885 \tTest Acc: 0.8024 \tTime: 179.7832\n",
      "Epoch: 10 \tTrain Loss: 0.54500 \tTrain Acc: 0.8131 \tTest Loss: 0.58617 \tTest Acc: 0.7991 \tTime: 180.0387\n",
      "Epoch: 11 \tTrain Loss: 0.52231 \tTrain Acc: 0.8181 \tTest Loss: 0.48105 \tTest Acc: 0.8359 \tTime: 179.1684\n",
      "Epoch: 12 \tTrain Loss: 0.49192 \tTrain Acc: 0.8295 \tTest Loss: 0.51198 \tTest Acc: 0.8237 \tTime: 178.5957\n",
      "Epoch: 13 \tTrain Loss: 0.47031 \tTrain Acc: 0.8362 \tTest Loss: 0.48650 \tTest Acc: 0.8365 \tTime: 178.9989\n",
      "Epoch: 14 \tTrain Loss: 0.45091 \tTrain Acc: 0.8431 \tTest Loss: 0.49044 \tTest Acc: 0.8344 \tTime: 179.1778\n",
      "Epoch: 15 \tTrain Loss: 0.42331 \tTrain Acc: 0.8527 \tTest Loss: 0.43141 \tTest Acc: 0.8535 \tTime: 179.6826\n",
      "Epoch: 16 \tTrain Loss: 0.40153 \tTrain Acc: 0.8613 \tTest Loss: 0.43287 \tTest Acc: 0.8496 \tTime: 179.1636\n",
      "Epoch: 17 \tTrain Loss: 0.39360 \tTrain Acc: 0.8640 \tTest Loss: 0.41621 \tTest Acc: 0.8575 \tTime: 179.1139\n",
      "Epoch: 18 \tTrain Loss: 0.37446 \tTrain Acc: 0.8710 \tTest Loss: 0.40728 \tTest Acc: 0.8599 \tTime: 179.2535\n",
      "Epoch: 19 \tTrain Loss: 0.36133 \tTrain Acc: 0.8753 \tTest Loss: 0.41370 \tTest Acc: 0.8572 \tTime: 179.2107\n",
      "Epoch: 20 \tTrain Loss: 0.34008 \tTrain Acc: 0.8814 \tTest Loss: 0.39809 \tTest Acc: 0.8621 \tTime: 179.4252\n",
      "Epoch: 21 \tTrain Loss: 0.32567 \tTrain Acc: 0.8864 \tTest Loss: 0.38067 \tTest Acc: 0.8705 \tTime: 180.0455\n",
      "Epoch: 22 \tTrain Loss: 0.31186 \tTrain Acc: 0.8916 \tTest Loss: 0.40159 \tTest Acc: 0.8657 \tTime: 179.5659\n",
      "Epoch: 23 \tTrain Loss: 0.30992 \tTrain Acc: 0.8920 \tTest Loss: 0.38380 \tTest Acc: 0.8695 \tTime: 179.3420\n",
      "Epoch: 24 \tTrain Loss: 0.29956 \tTrain Acc: 0.8964 \tTest Loss: 0.35877 \tTest Acc: 0.8784 \tTime: 179.2345\n",
      "Epoch: 25 \tTrain Loss: 0.27364 \tTrain Acc: 0.9045 \tTest Loss: 0.36125 \tTest Acc: 0.8790 \tTime: 178.8212\n",
      "Epoch: 26 \tTrain Loss: 0.26886 \tTrain Acc: 0.9064 \tTest Loss: 0.39230 \tTest Acc: 0.8724 \tTime: 178.9287\n",
      "Epoch: 27 \tTrain Loss: 0.26349 \tTrain Acc: 0.9082 \tTest Loss: 0.36307 \tTest Acc: 0.8767 \tTime: 178.8505\n",
      "Epoch: 28 \tTrain Loss: 0.25194 \tTrain Acc: 0.9119 \tTest Loss: 0.34910 \tTest Acc: 0.8839 \tTime: 179.0632\n",
      "Epoch: 29 \tTrain Loss: 0.24542 \tTrain Acc: 0.9132 \tTest Loss: 0.35588 \tTest Acc: 0.8795 \tTime: 179.1032\n",
      "Epoch: 30 \tTrain Loss: 0.23274 \tTrain Acc: 0.9183 \tTest Loss: 0.35820 \tTest Acc: 0.8841 \tTime: 179.1567\n",
      "Epoch: 31 \tTrain Loss: 0.22878 \tTrain Acc: 0.9191 \tTest Loss: 0.34792 \tTest Acc: 0.8836 \tTime: 179.2141\n",
      "Epoch: 32 \tTrain Loss: 0.21843 \tTrain Acc: 0.9242 \tTest Loss: 0.33393 \tTest Acc: 0.8873 \tTime: 179.7795\n",
      "Epoch: 33 \tTrain Loss: 0.21309 \tTrain Acc: 0.9255 \tTest Loss: 0.34935 \tTest Acc: 0.8835 \tTime: 179.5184\n",
      "Epoch: 34 \tTrain Loss: 0.20650 \tTrain Acc: 0.9281 \tTest Loss: 0.34000 \tTest Acc: 0.8881 \tTime: 179.0082\n",
      "Epoch: 35 \tTrain Loss: 0.19611 \tTrain Acc: 0.9298 \tTest Loss: 0.35031 \tTest Acc: 0.8879 \tTime: 178.8754\n",
      "Epoch: 36 \tTrain Loss: 0.18759 \tTrain Acc: 0.9352 \tTest Loss: 0.33688 \tTest Acc: 0.8933 \tTime: 180.5391\n",
      "Epoch: 37 \tTrain Loss: 0.18339 \tTrain Acc: 0.9360 \tTest Loss: 0.33637 \tTest Acc: 0.8893 \tTime: 179.4807\n",
      "Epoch: 38 \tTrain Loss: 0.18025 \tTrain Acc: 0.9368 \tTest Loss: 0.33227 \tTest Acc: 0.8935 \tTime: 179.0126\n",
      "Epoch: 39 \tTrain Loss: 0.17355 \tTrain Acc: 0.9389 \tTest Loss: 0.35207 \tTest Acc: 0.8865 \tTime: 179.1723\n",
      "Epoch: 40 \tTrain Loss: 0.16728 \tTrain Acc: 0.9411 \tTest Loss: 0.33821 \tTest Acc: 0.8919 \tTime: 179.1754\n",
      "Epoch: 41 \tTrain Loss: 0.15749 \tTrain Acc: 0.9435 \tTest Loss: 0.32723 \tTest Acc: 0.8963 \tTime: 178.8835\n",
      "Epoch: 42 \tTrain Loss: 0.15984 \tTrain Acc: 0.9447 \tTest Loss: 0.32126 \tTest Acc: 0.8975 \tTime: 178.9287\n",
      "Epoch: 43 \tTrain Loss: 0.15681 \tTrain Acc: 0.9446 \tTest Loss: 0.31368 \tTest Acc: 0.9037 \tTime: 178.9768\n",
      "Epoch: 44 \tTrain Loss: 0.15198 \tTrain Acc: 0.9466 \tTest Loss: 0.32916 \tTest Acc: 0.8971 \tTime: 180.4213\n",
      "Epoch: 45 \tTrain Loss: 0.13993 \tTrain Acc: 0.9509 \tTest Loss: 0.31060 \tTest Acc: 0.9020 \tTime: 181.0403\n",
      "Epoch: 46 \tTrain Loss: 0.13677 \tTrain Acc: 0.9511 \tTest Loss: 0.30428 \tTest Acc: 0.9029 \tTime: 178.8057\n",
      "Epoch: 47 \tTrain Loss: 0.13372 \tTrain Acc: 0.9528 \tTest Loss: 0.33810 \tTest Acc: 0.8977 \tTime: 179.0797\n",
      "Epoch: 48 \tTrain Loss: 0.13527 \tTrain Acc: 0.9523 \tTest Loss: 0.33420 \tTest Acc: 0.8998 \tTime: 179.0424\n",
      "Epoch: 49 \tTrain Loss: 0.12874 \tTrain Acc: 0.9548 \tTest Loss: 0.32906 \tTest Acc: 0.9000 \tTime: 178.9411\n",
      "Total Time For This Run: 8969.7029\n",
      "Run Number: 5 Starts Here\n",
      "Epoch: 0 \tTrain Loss: 1.65373 \tTrain Acc: 0.3838 \tTest Loss: 1.57168 \tTest Acc: 0.4386 \tTime: 138.5301\n",
      "Epoch: 1 \tTrain Loss: 1.29568 \tTrain Acc: 0.5284 \tTest Loss: 1.43838 \tTest Acc: 0.4965 \tTime: 138.2103\n",
      "Epoch: 2 \tTrain Loss: 1.11002 \tTrain Acc: 0.6054 \tTest Loss: 1.13138 \tTest Acc: 0.6034 \tTime: 138.2045\n",
      "Epoch: 3 \tTrain Loss: 1.00607 \tTrain Acc: 0.6465 \tTest Loss: 1.00994 \tTest Acc: 0.6534 \tTime: 138.4480\n",
      "Epoch: 4 \tTrain Loss: 0.90244 \tTrain Acc: 0.6830 \tTest Loss: 0.96127 \tTest Acc: 0.6681 \tTime: 138.5590\n",
      "Epoch: 5 \tTrain Loss: 0.81289 \tTrain Acc: 0.7174 \tTest Loss: 0.86569 \tTest Acc: 0.7012 \tTime: 138.5195\n",
      "Epoch: 6 \tTrain Loss: 0.74737 \tTrain Acc: 0.7383 \tTest Loss: 0.81173 \tTest Acc: 0.7217 \tTime: 138.5152\n",
      "Epoch: 7 \tTrain Loss: 0.69171 \tTrain Acc: 0.7602 \tTest Loss: 0.70612 \tTest Acc: 0.7619 \tTime: 138.6930\n",
      "Epoch: 8 \tTrain Loss: 0.64337 \tTrain Acc: 0.7773 \tTest Loss: 0.67921 \tTest Acc: 0.7654 \tTime: 138.6875\n",
      "Epoch: 9 \tTrain Loss: 0.61273 \tTrain Acc: 0.7887 \tTest Loss: 0.60481 \tTest Acc: 0.7935 \tTime: 138.7756\n",
      "Epoch: 10 \tTrain Loss: 0.55780 \tTrain Acc: 0.8090 \tTest Loss: 0.59369 \tTest Acc: 0.7988 \tTime: 138.6177\n",
      "Epoch: 11 \tTrain Loss: 0.53414 \tTrain Acc: 0.8150 \tTest Loss: 0.56080 \tTest Acc: 0.8078 \tTime: 138.5704\n",
      "Epoch: 12 \tTrain Loss: 0.50566 \tTrain Acc: 0.8262 \tTest Loss: 0.52197 \tTest Acc: 0.8257 \tTime: 138.3113\n",
      "Epoch: 13 \tTrain Loss: 0.48086 \tTrain Acc: 0.8340 \tTest Loss: 0.53455 \tTest Acc: 0.8190 \tTime: 138.2817\n",
      "Epoch: 14 \tTrain Loss: 0.46523 \tTrain Acc: 0.8383 \tTest Loss: 0.47515 \tTest Acc: 0.8366 \tTime: 138.2340\n",
      "Epoch: 15 \tTrain Loss: 0.43391 \tTrain Acc: 0.8507 \tTest Loss: 0.50586 \tTest Acc: 0.8269 \tTime: 138.3379\n",
      "Epoch: 16 \tTrain Loss: 0.41814 \tTrain Acc: 0.8549 \tTest Loss: 0.47085 \tTest Acc: 0.8385 \tTime: 138.4365\n",
      "Epoch: 17 \tTrain Loss: 0.40328 \tTrain Acc: 0.8591 \tTest Loss: 0.46323 \tTest Acc: 0.8428 \tTime: 138.5253\n",
      "Epoch: 18 \tTrain Loss: 0.38827 \tTrain Acc: 0.8649 \tTest Loss: 0.43366 \tTest Acc: 0.8520 \tTime: 138.7448\n",
      "Epoch: 19 \tTrain Loss: 0.37328 \tTrain Acc: 0.8688 \tTest Loss: 0.42329 \tTest Acc: 0.8573 \tTime: 138.6862\n",
      "Epoch: 20 \tTrain Loss: 0.35699 \tTrain Acc: 0.8765 \tTest Loss: 0.40718 \tTest Acc: 0.8650 \tTime: 138.5763\n",
      "Epoch: 21 \tTrain Loss: 0.34277 \tTrain Acc: 0.8803 \tTest Loss: 0.37886 \tTest Acc: 0.8717 \tTime: 138.6716\n",
      "Epoch: 22 \tTrain Loss: 0.33023 \tTrain Acc: 0.8840 \tTest Loss: 0.39045 \tTest Acc: 0.8678 \tTime: 138.6415\n",
      "Epoch: 23 \tTrain Loss: 0.32236 \tTrain Acc: 0.8877 \tTest Loss: 0.37911 \tTest Acc: 0.8717 \tTime: 138.4721\n",
      "Epoch: 24 \tTrain Loss: 0.31402 \tTrain Acc: 0.8899 \tTest Loss: 0.40644 \tTest Acc: 0.8641 \tTime: 138.5070\n",
      "Epoch: 25 \tTrain Loss: 0.29322 \tTrain Acc: 0.8981 \tTest Loss: 0.36774 \tTest Acc: 0.8736 \tTime: 138.3896\n",
      "Epoch: 26 \tTrain Loss: 0.28261 \tTrain Acc: 0.9020 \tTest Loss: 0.35905 \tTest Acc: 0.8787 \tTime: 138.9440\n",
      "Epoch: 27 \tTrain Loss: 0.27433 \tTrain Acc: 0.9048 \tTest Loss: 0.38132 \tTest Acc: 0.8738 \tTime: 138.9748\n",
      "Epoch: 28 \tTrain Loss: 0.27302 \tTrain Acc: 0.9048 \tTest Loss: 0.36855 \tTest Acc: 0.8797 \tTime: 138.3545\n",
      "Epoch: 29 \tTrain Loss: 0.26704 \tTrain Acc: 0.9070 \tTest Loss: 0.36438 \tTest Acc: 0.8760 \tTime: 138.8027\n",
      "Epoch: 30 \tTrain Loss: 0.24642 \tTrain Acc: 0.9143 \tTest Loss: 0.36450 \tTest Acc: 0.8797 \tTime: 138.6083\n",
      "Epoch: 31 \tTrain Loss: 0.24012 \tTrain Acc: 0.9158 \tTest Loss: 0.36686 \tTest Acc: 0.8767 \tTime: 138.9180\n",
      "Epoch: 32 \tTrain Loss: 0.23556 \tTrain Acc: 0.9170 \tTest Loss: 0.33030 \tTest Acc: 0.8881 \tTime: 138.3667\n",
      "Epoch: 33 \tTrain Loss: 0.22776 \tTrain Acc: 0.9197 \tTest Loss: 0.34574 \tTest Acc: 0.8834 \tTime: 138.6114\n",
      "Epoch: 34 \tTrain Loss: 0.21984 \tTrain Acc: 0.9236 \tTest Loss: 0.34776 \tTest Acc: 0.8851 \tTime: 138.3474\n",
      "Epoch: 35 \tTrain Loss: 0.21350 \tTrain Acc: 0.9258 \tTest Loss: 0.32896 \tTest Acc: 0.8906 \tTime: 138.7357\n",
      "Epoch: 36 \tTrain Loss: 0.20130 \tTrain Acc: 0.9282 \tTest Loss: 0.33706 \tTest Acc: 0.8900 \tTime: 138.8482\n",
      "Epoch: 37 \tTrain Loss: 0.19974 \tTrain Acc: 0.9299 \tTest Loss: 0.33569 \tTest Acc: 0.8892 \tTime: 138.4855\n",
      "Epoch: 38 \tTrain Loss: 0.19737 \tTrain Acc: 0.9294 \tTest Loss: 0.34274 \tTest Acc: 0.8886 \tTime: 138.3096\n",
      "Epoch: 39 \tTrain Loss: 0.18951 \tTrain Acc: 0.9341 \tTest Loss: 0.33265 \tTest Acc: 0.8930 \tTime: 138.8508\n",
      "Epoch: 40 \tTrain Loss: 0.17909 \tTrain Acc: 0.9367 \tTest Loss: 0.34003 \tTest Acc: 0.8912 \tTime: 139.4560\n",
      "Epoch: 41 \tTrain Loss: 0.17529 \tTrain Acc: 0.9391 \tTest Loss: 0.34298 \tTest Acc: 0.8876 \tTime: 139.6790\n",
      "Epoch: 42 \tTrain Loss: 0.16923 \tTrain Acc: 0.9400 \tTest Loss: 0.33901 \tTest Acc: 0.8921 \tTime: 139.5840\n",
      "Epoch: 43 \tTrain Loss: 0.16730 \tTrain Acc: 0.9416 \tTest Loss: 0.34159 \tTest Acc: 0.8910 \tTime: 139.4689\n",
      "Epoch: 44 \tTrain Loss: 0.16476 \tTrain Acc: 0.9420 \tTest Loss: 0.33791 \tTest Acc: 0.8928 \tTime: 139.5979\n",
      "Epoch: 45 \tTrain Loss: 0.15439 \tTrain Acc: 0.9453 \tTest Loss: 0.32727 \tTest Acc: 0.8982 \tTime: 140.5316\n",
      "Epoch: 46 \tTrain Loss: 0.15363 \tTrain Acc: 0.9456 \tTest Loss: 0.33914 \tTest Acc: 0.8931 \tTime: 139.3433\n",
      "Epoch: 47 \tTrain Loss: 0.14694 \tTrain Acc: 0.9472 \tTest Loss: 0.31796 \tTest Acc: 0.9009 \tTime: 139.3612\n",
      "Epoch: 48 \tTrain Loss: 0.14351 \tTrain Acc: 0.9493 \tTest Loss: 0.31631 \tTest Acc: 0.9002 \tTime: 138.9315\n",
      "Epoch: 49 \tTrain Loss: 0.14192 \tTrain Acc: 0.9495 \tTest Loss: 0.31371 \tTest Acc: 0.9009 \tTime: 140.0356\n",
      "Total Time For This Run: 6938.3608\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,5):\n",
    "    T1 = time.time()\n",
    "    print(f'Run Number: {i+1} Starts Here')\n",
    "    N,B,C = Grid_Search[i]\n",
    "    num_blocks = [B]*N\n",
    "    skip_kernel_size = [1]*N\n",
    "    conv_kernel_size = [3]*N\n",
    "    avg_pool_size = int(32/(2**(N-1)))\n",
    "\n",
    "    net = neural_net(N,C,num_blocks,conv_kernel_size,avg_pool_size,skip_kernel_size)\n",
    "\n",
    "    Loss = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.9)\n",
    "\n",
    "    for epoch in range(Num_Epochs):\n",
    "        T11 = time.time()\n",
    "\n",
    "        train_loss = 0.0\n",
    "        test_loss = 0.0\n",
    "\n",
    "        train_acc = 0.0\n",
    "        test_acc = 0.0\n",
    "\n",
    "        for k, data in enumerate(trainDataLoader):\n",
    "            images, labels = data\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            predicted_output = net(images)\n",
    "            fit = Loss(predicted_output,labels)\n",
    "            fit.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += fit.item()\n",
    "            train_acc += torch.sum(labels == predicted_output.argmax(dim=1)).item()\n",
    "\n",
    "        for k, data in enumerate(testDataLoader):\n",
    "            with torch.no_grad():\n",
    "                images, labels = data\n",
    "                images = images.cuda()\n",
    "                labels = labels.cuda()\n",
    "                predicted_output = net(images)\n",
    "                fit = Loss(predicted_output,labels)\n",
    "                test_loss += fit.item()\n",
    "                test_acc += torch.sum(labels == predicted_output.argmax(dim=1)).item()\n",
    "\n",
    "        scheduler.step()\n",
    "        train_loss = train_loss/len(trainDataLoader)\n",
    "        test_loss = test_loss/len(testDataLoader)\n",
    "        train_acc = train_acc/len(trainingdata)\n",
    "        test_acc = test_acc/len(testdata)\n",
    "        \n",
    "        train_acc_history[i][epoch] = train_acc \n",
    "        test_acc_history[i][epoch] = test_acc\n",
    "        train_loss_history[i][epoch] = train_loss\n",
    "        test_loss_history[i][epoch] = test_loss\n",
    "        \n",
    "        T22 = time.time()\n",
    "\n",
    "        print(f'Epoch: {epoch} \\tTrain Loss: {train_loss:.5f} \\tTrain Acc: {train_acc:.4f} \\tTest Loss: {test_loss:.5f} \\tTest Acc: {test_acc:.4f} \\tTime: {T22-T11:.4f}')\n",
    "\n",
    "    T2 = time.time()\n",
    "    \n",
    "    print(f'Total Time For This Run: {T2-T1:.4f}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "J9sSPxeBLPig"
   },
   "outputs": [],
   "source": [
    "np.savetxt('Train_Acc_0_2.txt',train_acc_history)\n",
    "np.savetxt('Test_Acc_0_2.txt',test_acc_history)\n",
    "np.savetxt('Train_Loss_0_2.txt',train_loss_history)\n",
    "np.savetxt('Test_Loss_0_2.txt',test_loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "9rbgn6pRLPig"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame (train_acc_history)\n",
    "filepath = 'Train_Acc_0_5.xlsx'\n",
    "df.to_excel(filepath, index=False)\n",
    "\n",
    "df = pd.DataFrame (test_acc_history)\n",
    "filepath = 'Test_Acc_0_5.xlsx'\n",
    "df.to_excel(filepath, index=False)\n",
    "\n",
    "\n",
    "df = pd.DataFrame (train_loss_history)\n",
    "filepath = 'Train_Loss_0_5.xlsx'\n",
    "df.to_excel(filepath, index=False)\n",
    "\n",
    "\n",
    "df = pd.DataFrame (test_loss_history)\n",
    "filepath = 'Test_Loss_0_5.xlsx'\n",
    "df.to_excel(filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "YTz7VeBELPig"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "yvrl_-eGLPig"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Parametric_Base_Code.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
